#!/usr/bin/env python
from __future__ import print_function

import os
import sys
import traceback

import numpy as np
import pandas as pd
import tensorflow as tf

from keras.layers import Dropout, Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.models import Sequential

# from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV

# Optional
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# These are the paths to where SageMaker mounts interesting things in your
# container.
prefix = '/opt/ml/'

input_path = prefix + 'input/data/training/churn.csv'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')

# This algorithm has a single channel of input data called 'training'.
# Since we run in File mode, the input files are copied to the directory
# specified here.
channel_name = 'training'
training_path = os.path.join(input_path, channel_name)


# Process and prepare the data
def data_process(raw_data):
    for col in raw_data.columns:
        if col not in ['user_id', 'domain_name']:
            col_mean = np.nanmean(raw_data[col], axis=0)
            raw_data[col].fillna(col_mean, inplace=True)

    # Replace with average age
    X = raw_data.iloc[:, 1:len(raw_data.columns)-1].values
    y = raw_data.iloc[:, len(raw_data.columns)-1].values

    # Encoding categorical variables
    labelencoder_X_1 = LabelEncoder()
    X[:, 15] = labelencoder_X_1.fit_transform(X[:, 15])

    # Feature Scaling
    sc = StandardScaler()
    X = sc.fit_transform(X)

    return X, y


# Building the ANN
def build_classifier(optimizer):
    # Initialize ANN
    classifier = Sequential()

    # First hidden layer with 10% dropout
    classifier.add(Dense(
        activation="relu",
        input_dim=16,
        units=8,
        kernel_initializer="uniform"))
    classifier.add(Dropout(rate=0.1))

    # The second hidden layer with 10% dropout
    classifier.add(Dense(
        activation="relu",
        units=8,
        kernel_initializer="uniform"))
    classifier.add(Dropout(rate=0.1))

    # Adding the output layer
    classifier.add(Dense(
        activation="sigmoid",
        units=1,
        kernel_initializer="uniform"))

    # Compiling the ANN
    classifier.compile(
        optimizer=optimizer,
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    return classifier


def generate_model(X_train, y_train):
    # Build classifier using grid search
    classifier = KerasClassifier(build_fn=build_classifier)

    # Create a dict of hyperparameters to optimize
    parameters = {
        # Tune batch size, epoch, optimizer
        'batch_size': [25, 32],
        'nb_epoch': [100, 500],
        'optimizer': ['adam', 'rmsprop']
    }

    # Implement GridSearch
    grid_search = GridSearchCV(
        estimator=classifier,
        param_grid=parameters,
        scoring='accuracy',
        cv=10
    )

    # Fit gridsearch to training set
    optimized_classifier = grid_search.fit(
        X_train,
        y_train
    )

    return optimized_classifier


def train():
    print('Starting the training.')
    try:
        raw_data = pd.read_csv(input_path)
        X, y = data_process(raw_data)
        optimized_classifier = generate_model(X, y)
        optimized_classifier.best_estimator_.model.save(
            os.path.join(model_path, 'ann-churn.h5'))
        print('Training is complete.')
    except Exception as e:
        # Write out an error file. This will be returned as the failure
        # Reason in the DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs
        print(
            'Exception during training: ' + str(e) + '\n' + trc,
            file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)


if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
